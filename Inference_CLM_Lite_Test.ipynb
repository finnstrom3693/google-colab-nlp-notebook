{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DS-yfleN6IK9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a4a0162-96e4-47f3-a877-d34224eceaaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (7.34.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython) (4.9.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed jedi-0.19.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch ipython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zdhtJMbe9ieY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from IPython.display import display, HTML"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "My Model"
      ],
      "metadata": {
        "id": "gR4hg1IsKA2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "repo = \"nqzfaizal77ai/mt-230m-pretrained-en-1bc-exp\""
      ],
      "metadata": {
        "id": "niMEjbQ1h5Ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo = \"nqzfaizal77ai/ql-250m-pretrained-en-1bc-exp\""
      ],
      "metadata": {
        "id": "sx7UAKsm1GKu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo = \"nqzfaizal77ai/qlpt-m-en-1bc-exp\""
      ],
      "metadata": {
        "id": "hLML8fcHmffk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo = \"nqzfaizal77ai/qlpt-m-en-1bc-exp2\""
      ],
      "metadata": {
        "id": "uGYUqZ540D1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo = \"nqzfaizal77ai/qlpt-m-wikipedia-en-1bc-exp\""
      ],
      "metadata": {
        "id": "wuLJHkF8Qq0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo = \"nqzfaizal77ai/qlpt-m-wikipedia-en-1bc-exp2\""
      ],
      "metadata": {
        "id": "Rw3q1JJf0Fcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo = \"nqzfaizal77ai/qlpt-m-sft-en-1bc-exp\""
      ],
      "metadata": {
        "id": "I2tJ1GEM9LIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other Pretrained Model"
      ],
      "metadata": {
        "id": "Kb18uuYcKC7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "repo = \"Qwen/Qwen3-1.7B\""
      ],
      "metadata": {
        "id": "BqZ4BrW3g6C0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo = \"HuggingFaceTB/SmolLM-1.7B\""
      ],
      "metadata": {
        "id": "Ht-0VPAf3LlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo = \"openai-community/gpt2-large\""
      ],
      "metadata": {
        "id": "Jr6i6Cpr3VJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo = \"EleutherAI/gpt-neo-1.3B\""
      ],
      "metadata": {
        "id": "4c7ILuMM3W2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZxdbfhsfbMw_"
      },
      "outputs": [],
      "source": [
        "precision = 'full' # @param [\"half\", \"full\"]\n",
        "if precision == \"half\":\n",
        "    selected_precision = torch.float16\n",
        "elif precision == \"full\":\n",
        "    selected_precision = torch.float32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fS7L9e-pbMxF"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czXanMio-f9H"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(repo, torch_dtype=selected_precision)\n",
        "model.to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(repo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7MJFSlJbMxJ"
      },
      "outputs": [],
      "source": [
        "# @title Hyperparameter Inference\n",
        "max_length = 100  # @param {type:\"integer\"} (maximum length of generated text)\n",
        "min_length = 10   # @param {type:\"integer\"} (minimum length should be less than max_length)\n",
        "top_k = 50        # @param {type:\"integer\"} (typical range 0-100)\n",
        "top_p = 0.92      # @param {type:\"number\"} (should be <= 1.0, typically 0.7-0.95)\n",
        "temperature = 0.7  # @param {type:\"number\"} (typically 0.1-1.0, higher = more random)\n",
        "repetition_penalty = 1.2  # @param {type:\"number\"} (typically 1.0-1.5)\n",
        "do_sample = True   # @param {type:\"boolean\"}\n",
        "use_cache = True   # @param {type:\"boolean\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SFT Test"
      ],
      "metadata": {
        "id": "-sogUjot9YYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Input:\n",
        "what is weakness person who like to incite other?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "qk8RjdY_9bdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Targeted"
      ],
      "metadata": {
        "id": "VgZqysYG__Zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"The person who likes to incite others has a weakness\""
      ],
      "metadata": {
        "id": "B3xQjarLkRJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Discourage,Restrain,Dissuade,Calming is nemesis action of inciter and\""
      ],
      "metadata": {
        "id": "20djMaoH1aKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Engaging in backbiting not only damages\""
      ],
      "metadata": {
        "id": "-KUxB4Ks_-HF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Bullying is entertainment for evil person\""
      ],
      "metadata": {
        "id": "eN5oqMSpJ1Hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test General"
      ],
      "metadata": {
        "id": "ei7bDvMJ2XMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Technology changes faster than most people expect\""
      ],
      "metadata": {
        "id": "M7gMCLu12YNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"He walked into the room, unsure of what he would find\""
      ],
      "metadata": {
        "id": "MdDbSscs2aWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"The sky turned orange as the sun began to set\""
      ],
      "metadata": {
        "id": "n21fBeij2gKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"The first drop of rain echoed the start of\""
      ],
      "metadata": {
        "id": "K-nM1LWU0UDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Topic"
      ],
      "metadata": {
        "id": "zn2de9atzFbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Science\n",
        "prompt = \"Water boils faster at higher altitudes due to lower air pressure\""
      ],
      "metadata": {
        "id": "B0D8QRCPzG89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# History\n",
        "prompt = \"The Great Wall of China was built to protect against invasions.\""
      ],
      "metadata": {
        "id": "17Y5n1pDzMGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Technology\n",
        "prompt = \"Smartphones now use AI to enhance photo quality in real time\""
      ],
      "metadata": {
        "id": "TSViwLMYzOZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Emotion\n",
        "prompt = \"She smiled through the pain, hiding her sadness from the world\""
      ],
      "metadata": {
        "id": "pjauGXBZzfts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Education\n",
        "prompt = \"Students learn better when lessons are interactive and engaging\""
      ],
      "metadata": {
        "id": "ZdKUWooRzl7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Positivity Islam"
      ],
      "metadata": {
        "id": "VTccL6blFty8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"I feel peace when I recite the Qur'an\""
      ],
      "metadata": {
        "id": "H7gHIjCRFxhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"I’m grateful for the blessings Allah gives\""
      ],
      "metadata": {
        "id": "DJs3xugeHFyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Helping others for the sake of Allah makes me happy\""
      ],
      "metadata": {
        "id": "NNcv5x7oHQGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Praying brings joy to my heart\""
      ],
      "metadata": {
        "id": "d4NwrmZSHXVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Positivity"
      ],
      "metadata": {
        "id": "53xlHukuHgrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Her kind words filled me with gratitude and warmth\""
      ],
      "metadata": {
        "id": "sMWrFdQqHfrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"I feel incredibly grateful for all the support and kindness I've received\""
      ],
      "metadata": {
        "id": "yfCE9_HQIZmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Even though it's tough right now, I have an unwavering belief in your strength and ability to overcome this\""
      ],
      "metadata": {
        "id": "Elzx5glmItvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Every step you take, no matter how small, is progress, and I'm so inspired\""
      ],
      "metadata": {
        "id": "WN1BOk6FIxmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Your resilience in the face of this difficulty is truly good\""
      ],
      "metadata": {
        "id": "ltDVkMZJI5zF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stochastic Decoding"
      ],
      "metadata": {
        "id": "cpX_qUzUivjk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1xZcnKx5Txd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de61d29c-a22d-4b3f-a0b0-ed5cc3b1f004"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "output = model.generate(\n",
        "                        inputs[\"input_ids\"],\n",
        "                        max_length=max_length,\n",
        "                        min_length=min_length,\n",
        "                        # num_return_sequences=1,\n",
        "                        top_k=top_k,\n",
        "                        top_p=top_p,\n",
        "                        temperature=temperature,\n",
        "                        repetition_penalty=repetition_penalty,\n",
        "                        # num_beams=5,\n",
        "                        # length_penalty=0.8,\n",
        "                        # penalty_alpha=0.5,\n",
        "                        do_sample=True,\n",
        "                        use_cache=True\n",
        "                        )\n",
        "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Greedy Decoding"
      ],
      "metadata": {
        "id": "M7fUgI29j0aY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: make greedy decoding code\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "# Greedy Decoding\n",
        "greedy_output = model.generate(\n",
        "    inputs[\"input_ids\"],\n",
        "    max_length=max_length,\n",
        "    min_length=min_length,\n",
        "    do_sample=False,\n",
        "    repetition_penalty=repetition_penalty,\n",
        "    use_cache=True\n",
        ")\n",
        "decoded_output = tokenizer.decode(greedy_output[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "XvoNkdP-iukM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af0e81e8-b785-4334-c428-eee00a5e94d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display Text"
      ],
      "metadata": {
        "id": "Cdf1nqCMwj2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "# Sample model name\n",
        "model_name = repo\n",
        "\n",
        "# Replace newlines with <br>\n",
        "formatted_output = decoded_output.replace(\"\\n\", \"<br>\")\n",
        "\n",
        "# HTML and CSS with model name outside the box\n",
        "html_code = f\"\"\"\n",
        "<div style='margin-bottom: 5px; font-family: sans-serif; font-weight: bold;'>repo : {model_name}</div>\n",
        "<div style='border: 2px solid black; padding: 10px; width: 500px; height: 300px; overflow: auto;'>\n",
        "    <p style='font-family: monospace;'>{formatted_output}</p>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "# Display the styled output\n",
        "display(HTML(html_code))\n"
      ],
      "metadata": {
        "id": "eukuIxnpcTdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "# Sample model name\n",
        "model_name = repo\n",
        "\n",
        "# Replace newlines with <br>\n",
        "formatted_output = decoded_output.replace(\"\\n\", \"<br>\")\n",
        "\n",
        "# HTML and CSS with model name outside the box\n",
        "html_code = f\"\"\"\n",
        "<div style='margin-bottom: 5px; font-family: sans-serif; font-weight: bold;'>repo : {model_name}</div>\n",
        "<div style='border: 2px solid black; padding: 10px; width: 500px; height: 300px; overflow: auto;'>\n",
        "    <p style='font-family: monospace;'>{formatted_output}</p>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "# Display the styled output\n",
        "display(HTML(html_code))\n"
      ],
      "metadata": {
        "id": "iGynYZL3wmU_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}